# Datasets y Scripts de Ejemplo - Pipeline ETL

Este documento complementa el dise√±o conceptual del pipeline ETL con **ejemplos pr√°cticos** listos para ejecutar.

---

## üìÅ Archivos incluidos

### 1. **Datos de ejemplo (CSV/JSON)**

| Archivo | Descripci√≥n | Registros | Descarga |
|---------|-------------|-----------|----------|
| `ventas_pos_ejemplo.csv` | Ventas del POS con diferentes escenarios | 7 ventas | [üì• Ver archivo](ventas-pos-ejemplo.csv) |
| `crm_clientes_ejemplo.csv` | Datos de clientes y segmentaci√≥n | 5 clientes | [üì• Ver archivo](crm-clientes-ejemplo.csv) |
| `inventario_api_response.json` | Respuesta simulada de la API de inventario | 5 productos | [üì• Ver archivo](inventario-api-response.json) |
| `web_logs_ejemplo.json` | Logs de eventos del sitio web | 5 eventos | [üì• Ver archivo](web-logs-ejemplo.json) |

### 2. **Scripts**

| Archivo | Descripci√≥n | Lenguaje | Descarga |
|---------|-------------|----------|----------|
| `etl_demo_script.py` | Pipeline ETL completo con carga incremental | Python 3 | [üì• Ver archivo](#etl-demo-scriptpy) |
| `setup_warehouse.sql` | Creaci√≥n de tablas del data warehouse | SQL (PostgreSQL) | [üì• Ver archivo](#setup-warehousesql) |

---

## üöÄ C√≥mo usar estos ejemplos

### Opci√≥n A: Ejecutar el script Python

```bash
# 1. Copiar el contenido de etl_demo_script.py (ver m√°s abajo)
# 2. Guardar como etl_demo_script.py
# 3. Ejecutar (no requiere dependencias externas)
python etl_demo_script.py
```

**Salida esperada:**
```
======================================================================
PIPELINE ETL - CARGA INCREMENTAL DE VENTAS POS
======================================================================

[EXTRACT] Extrayendo ventas con created_at > '2025-01-15 10:00:00'
[EXTRACT] ‚úì Extra√≠das 5 ventas nuevas

[TRANSFORM] Procesando 5 ventas...
[TRANSFORM] ‚ö† Duplicado detectado: id_venta=1001
[TRANSFORM] ‚úì Ventas v√°lidas: 3
[TRANSFORM] ‚ö† Errores: 1
[TRANSFORM] ‚ö† Duplicados: 1

[LOAD] Cargando 3 ventas a ventas_consolidadas...
  ‚Üí Upsert id_venta=1001, total=$51.0, segmento=premium
  ‚Üí Upsert id_venta=1002, total=$89.99, segmento=anonimo
  ‚Üí Upsert id_venta=1003, total=$45.0, segmento=regular
[LOAD] ‚úì Carga completada

======================================================================
RESUMEN DE EJECUCI√ìN
======================================================================
Registros extra√≠dos:     5
Registros cargados:      3
Registros con error:     1
Duplicados detectados:   1
Nuevo watermark:         2025-01-15 14:20:00
======================================================================
```
![Resumen](img/prueba.png)
### Opci√≥n B: Setup del data warehouse (PostgreSQL)

```bash
# 1. Conectarse a PostgreSQL
psql -U tu_usuario -d tu_database

# 2. Copiar y ejecutar el contenido de setup_warehouse.sql (ver m√°s abajo)
\i setup_warehouse.sql

# 3. Verificar tablas creadas
\dt
```

---

## üìä Estructura de los datos de ejemplo

### Ventas POS (`ventas_pos_ejemplo.csv`)

Incluye casos especiales para demostrar el manejo de:
- ‚úÖ Ventas normales
- ‚ö†Ô∏è **Compras an√≥nimas** (id_cliente nulo)
- üîÅ **Duplicados** (mismo id_venta)
- ‚ùå **Datos inv√°lidos** (cantidad negativa)

```csv
id_venta,created_at,id_tienda,id_cliente,id_producto,cantidad,precio_unitario
1001,2025-01-15 11:30:00,5,2341,POS_SKU_789,2,25.50
1002,2025-01-15 12:15:00,3,,POS_SKU_456,1,89.99  ‚Üê compra an√≥nima
1004,2025-01-15 14:20:00,8,4567,POS_SKU_999,-1,45.00  ‚Üê cantidad negativa (error)
```

### CRM Clientes (`crm_clientes_ejemplo.csv`)

Datos de segmentaci√≥n para enriquecimiento:

```csv
id_cliente,nombre,email,segmento,fecha_actualizacion
2341,Ana Garc√≠a,ana.garcia@email.com,premium,2025-01-10
1523,Carlos L√≥pez,carlos.lopez@email.com,regular,2025-01-10
```

### Inventario API (`inventario_api_response.json`)

Respuesta t√≠pica de una API REST:

```json
{
  "timestamp": "2025-01-15T18:00:00Z",
  "status": "success",
  "data": [
    {
      "id_producto": "INV_PROD_001",
      "sku_sistema": "POS_SKU_789",
      "ubicacion": "TIENDA_05",
      "stock": 150,
      "stock_minimo": 20
    }
  ]
}
```

### Web Logs (`web_logs_ejemplo.json`)

Eventos del sitio web que se correlacionan con ventas del POS:

```json
[
  {
    "event_type": "page_view",
    "timestamp": "2025-01-15T11:25:00.123Z",
    "session_id": "sess_abc123",
    "user_id": 2341,
    "page": "/productos/camisetas"
  },
  {
    "event_type": "purchase",
    "timestamp": "2025-01-15T11:30:15.789Z",
    "session_id": "sess_abc123",
    "user_id": 2341,
    "order_id": 1001,  ‚Üê correlaciona con POS
    "total_amount": 51.00
  }
]
```

---

## üîç Casos de prueba incluidos

El script de demostraci√≥n maneja estos escenarios:

| Escenario | id_venta | Resultado esperado | Raz√≥n |
|-----------|----------|-------------------|-------|
| ‚úÖ Venta v√°lida | 1001 | Cargada exitosamente | Todos los campos correctos |
| üë§ Compra an√≥nima | 1002 | Cargada como 'anonimo' | id_cliente es NULL |
| ‚úÖ Venta v√°lida | 1003 | Cargada exitosamente | Cliente con segmento 'regular' |
| üîÅ Duplicado | 1001 (repetido) | **Rechazada** | Mismo id_venta ya existe |
| ‚ùå Cantidad negativa | 1004 | **Error table** | cantidad = -1 (inv√°lido) |

---

## üí° Qu√© demuestra el script

### 1. **Extracci√≥n incremental (watermarking)**
```python
watermark = "2025-01-15 10:00:00"
nuevas_ventas = [v for v in VENTAS_POS if v["created_at"] > watermark]
```

### 2. **Transformaciones**
- ‚úÖ Normalizaci√≥n de timestamps
- ‚úÖ C√°lculo de totales (`cantidad * precio_unitario`)
- ‚úÖ Mapeo de SKUs a productos unificados
- ‚úÖ Enriquecimiento con datos de CRM

### 3. **Validaciones de calidad**
```python
def validar_venta(venta):
    if venta["cantidad"] < 0:
        return False, "cantidad negativa"
    if venta["precio_unitario"] < 0:
        return False, "precio_unitario negativo"
    return True, None
```

### 4. **Detecci√≥n de duplicados**
```python
# Por id_venta
if venta["id_venta"] in dedup_set:
    duplicados_detectados += 1
    continue

# Por hash de campos cr√≠ticos
dedup_hash = hashlib.md5(f"{tienda}|{fecha}|{producto}|{cantidad}".encode()).hexdigest()
```

### 5. **Upsert (carga idempotente)**
```sql
INSERT INTO ventas_consolidadas (...)
VALUES (...)
ON CONFLICT (id_venta) DO UPDATE SET
    cantidad = EXCLUDED.cantidad,
    total_venta = EXCLUDED.total_venta;
```

---

## üìà Consultas de ejemplo para an√°lisis

Una vez cargados los datos, puedes ejecutar:

### Ventas por tienda
```sql
SELECT 
    t.nombre,
    COUNT(*) as num_ventas,
    SUM(v.total_venta) as total,
    AVG(v.total_venta) as ticket_promedio
FROM ventas_consolidadas v
JOIN dim_tienda t ON v.id_tienda = t.id_tienda
GROUP BY t.nombre
ORDER BY total DESC;
```

### Top productos
```sql
SELECT 
    p.nombre,
    p.categoria,
    SUM(v.cantidad) as unidades_vendidas,
    SUM(v.total_venta) as ingresos
FROM ventas_consolidadas v
JOIN dim_producto p ON v.id_producto = p.sku_unificado
GROUP BY p.nombre, p.categoria
ORDER BY ingresos DESC
LIMIT 10;
```

### Ventas por segmento de cliente
```sql
SELECT 
    segmento_cliente,
    COUNT(*) as num_transacciones,
    SUM(total_venta) as total,
    AVG(total_venta) as ticket_promedio
FROM ventas_consolidadas
GROUP BY segmento_cliente
ORDER BY total DESC;
```

### Productos con bajo inventario
```sql
SELECT 
    p.nombre,
    i.ubicacion,
    i.stock,
    i.stock_minimo,
    i.stock - i.stock_minimo as margen
FROM dim_inventario i
JOIN dim_producto p ON i.sku_unificado = p.sku_unificado
WHERE i.stock < i.stock_minimo * 1.5
ORDER BY margen ASC;
```

---

## üõ†Ô∏è Personalizaci√≥n

### Modificar el watermark
En `etl_demo_script.py`, cambia:
```python
WATERMARK = "2025-01-15 10:00:00"  # Ajustar seg√∫n necesidad
```

### A√±adir nuevos productos
En `setup_warehouse.sql`:
```sql
INSERT INTO dim_producto (sku_unificado, nombre, categoria, precio_sugerido) 
VALUES ('PROD_005', 'Pantal√≥n Deportivo', 'Ropa', 65.00);
```

### Agregar mapeos de SKUs
```sql
INSERT INTO producto_map (sistema, id_sistema, sku_unificado) 
VALUES ('pos', 'POS_SKU_NEW', 'PROD_005');
```

---

## üìù Notas t√©cnicas

### Dependencias del script Python
- **Python 3.7+** (usa type hints y f-strings)
- **Librer√≠as est√°ndar √∫nicamente**: csv, hashlib, datetime, typing
- **No requiere instalaci√≥n** de paquetes externos

### Base de datos
El SQL est√° optimizado para **PostgreSQL 12+**, pero puede adaptarse f√°cilmente a:
- MySQL (cambiar sintaxis de `ON CONFLICT`)
- SQL Server (usar `MERGE`)
- Snowflake (usar `MERGE`)

---

## ‚úÖ Checklist de validaci√≥n

Usa esta lista para verificar que el pipeline funciona:

- [ ] Script Python ejecuta sin errores
- [ ] Se detectan 1 duplicado y 1 error
- [ ] Se cargan exactamente 3 ventas v√°lidas
- [ ] El watermark se actualiza correctamente
- [ ] Las tablas SQL se crean sin errores
- [ ] Las foreign keys funcionan correctamente
- [ ] Los √≠ndices mejoran el performance de consultas
- [ ] Las vistas retornan datos correctos

---

## üéØ Pr√≥ximos pasos

1. **Integrar con Airflow**: Convertir el script en un DAG
2. **A√±adir tests**: Usar pytest para pruebas automatizadas
3. **Implementar CDC**: Para captura de cambios en tiempo real
4. **Monitoreo**: Integrar con Prometheus/Grafana
5. **Alertas**: Configurar notificaciones por Slack/email

---

# üì• ARCHIVOS COMPLETOS

## `ventas_pos_ejemplo.csv`

```csv
id_venta,created_at,id_tienda,id_cliente,id_producto,cantidad,precio_unitario
1001,2025-01-15 11:30:00,5,2341,POS_SKU_789,2,25.50
1002,2025-01-15 12:15:00,3,,POS_SKU_456,1,89.99
1003,2025-01-15 13:45:00,5,1523,POS_SKU_123,3,15.00
1004,2025-01-15 14:20:00,8,4567,POS_SKU_999,1,45.00
1005,2025-01-15 15:10:00,3,2341,POS_SKU_789,1,25.50
1006,2025-01-15 16:00:00,5,,POS_SKU_456,2,89.99
1007,2025-01-15 17:30:00,8,1523,POS_SKU_123,5,15.00
```



---

## `crm_clientes_ejemplo.csv`

```csv
id_cliente,nombre,email,segmento,fecha_actualizacion
2341,Ana Garc√≠a,ana.garcia@email.com,premium,2025-01-10
1523,Carlos L√≥pez,carlos.lopez@email.com,regular,2025-01-10
4567,Mar√≠a Rodr√≠guez,maria.rodriguez@email.com,vip,2025-01-10
7890,Pedro S√°nchez,pedro.sanchez@email.com,regular,2025-01-10
3456,Laura Mart√≠nez,laura.martinez@email.com,premium,2025-01-10
```



---

## `inventario_api_response.json`

```json
{
  "timestamp": "2025-01-15T18:00:00Z",
  "status": "success",
  "data": [
    {
      "id_producto": "INV_PROD_001",
      "sku_sistema": "POS_SKU_789",
      "ubicacion": "TIENDA_05",
      "stock": 150,
      "stock_minimo": 20,
      "ultima_actualizacion": "2025-01-15T17:45:00Z"
    },
    {
      "id_producto": "INV_PROD_002",
      "sku_sistema": "POS_SKU_456",
      "ubicacion": "TIENDA_03",
      "stock": 45,
      "stock_minimo": 10,
      "ultima_actualizacion": "2025-01-15T17:45:00Z"
    },
    {
      "id_producto": "INV_PROD_003",
      "sku_sistema": "POS_SKU_123",
      "ubicacion": "TIENDA_05",
      "stock": 320,
      "stock_minimo": 50,
      "ultima_actualizacion": "2025-01-15T17:45:00Z"
    },
    {
      "id_producto": "INV_PROD_004",
      "sku_sistema": "POS_SKU_999",
      "ubicacion": "TIENDA_08",
      "stock": 78,
      "stock_minimo": 15,
      "ultima_actualizacion": "2025-01-15T17:45:00Z"
    },
    {
      "id_producto": "INV_PROD_001",
      "sku_sistema": "POS_SKU_789",
      "ubicacion": "ALMACEN_CENTRAL",
      "stock": 500,
      "stock_minimo": 100,
      "ultima_actualizacion": "2025-01-15T17:45:00Z"
    }
  ]
}
```



---

## `web_logs_ejemplo.json`

```json
[
  {
    "event_type": "page_view",
    "timestamp": "2025-01-15T11:25:00.123Z",
    "session_id": "sess_abc123",
    "user_id": 2341,
    "page": "/productos/camisetas",
    "referrer": "https://google.com",
    "device": "mobile"
  },
  {
    "event_type": "add_to_cart",
    "timestamp": "2025-01-15T11:28:30.456Z",
    "session_id": "sess_abc123",
    "user_id": 2341,
    "product_id": "POS_SKU_789",
    "quantity": 2,
    "device": "mobile"
  },
  {
    "event_type": "purchase",
    "timestamp": "2025-01-15T11:30:15.789Z",
    "session_id": "sess_abc123",
    "user_id": 2341,
    "order_id": 1001,
    "total_amount": 51.00,
    "payment_method": "credit_card",
    "items": [
      {
        "product_id": "POS_SKU_789",
        "quantity": 2,
        "price": 25.50
      }
    ],
    "device": "mobile"
  },
  {
    "event_type": "page_view",
    "timestamp": "2025-01-15T12:10:00.234Z",
    "session_id": "sess_xyz789",
    "user_id": null,
    "page": "/productos/zapatillas",
    "referrer": "direct",
    "device": "desktop"
  },
  {
    "event_type": "purchase",
    "timestamp": "2025-01-15T12:15:45.567Z",
    "session_id": "sess_xyz789",
    "user_id": null,
    "order_id": 1002,
    "total_amount": 89.99,
    "payment_method": "paypal",
    "items": [
      {
        "product_id": "POS_SKU_456",
        "quantity": 1,
        "price": 89.99
      }
    ],
    "device": "desktop"
  }
]
```

---

## `etl_demo_script.py`

```python
#!/usr/bin/env python3
"""
Script de demostraci√≥n de carga incremental para el pipeline ETL
Simula la extracci√≥n, transformaci√≥n y carga de ventas desde el POS
"""

import csv
import hashlib
from datetime import datetime
from typing import Dict, List, Optional

# =============================================================================
# CONFIGURACI√ìN Y DATOS DE EJEMPLO
# =============================================================================

# Simular watermark (√∫ltima fecha procesada)
WATERMARK = "2025-01-15 10:00:00"

# Datos de ejemplo del POS (ventas nuevas desde el watermark)
VENTAS_POS = [
    {
        "id_venta": 1001,
        "created_at": "2025-01-15 11:30:00",
        "id_tienda": 5,
        "id_cliente": 2341,
        "id_producto": "POS_SKU_789",
        "cantidad": 2,
        "precio_unitario": 25.50
    },
    {
        "id_venta": 1002,
        "created_at": "2025-01-15 12:15:00",
        "id_tienda": 3,
        "id_cliente": None,  # Compra an√≥nima
        "id_producto": "POS_SKU_456",
        "cantidad": 1,
        "precio_unitario": 89.99
    },
    {
        "id_venta": 1003,
        "created_at": "2025-01-15 13:45:00",
        "id_tienda": 5,
        "id_cliente": 1523,
        "id_producto": "POS_SKU_123",
        "cantidad": 3,
        "precio_unitario": 15.00
    },
    {
        "id_venta": 1001,  # DUPLICADO - mismo id_venta
        "created_at": "2025-01-15 11:30:00",
        "id_tienda": 5,
        "id_cliente": 2341,
        "id_producto": "POS_SKU_789",
        "cantidad": 2,
        "precio_unitario": 25.50
    },
    {
        "id_venta": 1004,
        "created_at": "2025-01-15 14:20:00",
        "id_tienda": 8,
        "id_cliente": 4567,
        "id_producto": "POS_SKU_999",
        "cantidad": -1,  # ERROR: cantidad negativa
        "precio_unitario": 45.00
    }
]

# Mapeo de productos (normalizaci√≥n de SKUs)
PRODUCTO_MAP = {
    "POS_SKU_789": {"sku_unificado": "PROD_001", "nombre": "Camiseta B√°sica"},
    "POS_SKU_456": {"sku_unificado": "PROD_002", "nombre": "Zapatillas Running"},
    "POS_SKU_123": {"sku_unificado": "PROD_003", "nombre": "Calcetines Pack 3"},
    "POS_SKU_999": {"sku_unificado": "PROD_004", "nombre": "Gorra Deportiva"}
}

# Datos de CRM (segmentaci√≥n de clientes)
CRM_DATA = {
    2341: {"nombre": "Ana Garc√≠a", "segmento": "premium", "email": "ana.g@email.com"},
    1523: {"nombre": "Carlos L√≥pez", "segmento": "regular", "email": "carlos.l@email.com"},
    4567: {"nombre": "Mar√≠a Rodr√≠guez", "segmento": "vip", "email": "maria.r@email.com"}
}

# =============================================================================
# FUNCIONES DE TRANSFORMACI√ìN
# =============================================================================

def normalize_timestamp(ts_str: str) -> str:
    """Convierte timestamp a formato est√°ndar UTC"""
    dt = datetime.strptime(ts_str, "%Y-%m-%d %H:%M:%S")
    return dt.strftime("%Y-%m-%d")

def map_producto(id_producto: str, sistema: str = "pos") -> Optional[Dict]:
    """Mapea SKU del sistema origen a SKU unificado"""
    return PRODUCTO_MAP.get(id_producto)

def lookup_segmento(id_cliente: Optional[int]) -> str:
    """Busca segmento del cliente en CRM"""
    if id_cliente is None:
        return "anonimo"
    cliente = CRM_DATA.get(id_cliente, {})
    return cliente.get("segmento", "sin_clasificar")

def calcular_dedup_hash(venta: Dict) -> str:
    """Calcula hash para detecci√≥n de duplicados"""
    # Crear string con campos cr√≠ticos
    dedup_str = f"{venta['id_tienda']}|{venta['fecha_venta']}|{venta['id_producto']}|{venta['cantidad']}|{venta['total_venta']}"
    return hashlib.md5(dedup_str.encode()).hexdigest()

def validar_venta(venta: Dict) -> tuple[bool, Optional[str]]:
    """Valida reglas de negocio"""
    # Validar campos requeridos
    if venta["id_producto"] is None:
        return False, "id_producto es nulo"
    
    if venta["cantidad"] is None:
        return False, "cantidad es nula"
    
    # Validar rangos
    if venta["cantidad"] < 0:
        return False, "cantidad negativa"
    
    if venta["precio_unitario"] < 0:
        return False, "precio_unitario negativo"
    
    return True, None

# =============================================================================
# PIPELINE ETL
# =============================================================================

def extract_ventas_incrementales(watermark: str) -> List[Dict]:
    """Extrae ventas nuevas desde el watermark"""
    print(f"\n[EXTRACT] Extrayendo ventas con created_at > '{watermark}'")
    
    nuevas_ventas = [
        v for v in VENTAS_POS 
        if v["created_at"] > watermark
    ]
    
    print(f"[EXTRACT] ‚úì Extra√≠das {len(nuevas_ventas)} ventas nuevas")
    return nuevas_ventas

def transform_ventas(ventas: List[Dict]) -> tuple[List[Dict], List[Dict]]:
    """Transforma y limpia ventas"""
    print(f"\n[TRANSFORM] Procesando {len(ventas)} ventas...")
    
    ventas_validas = []
    ventas_error = []
    dedup_set = set()
    duplicados_detectados = 0
    
    for venta in ventas:
        # 1. Normalizar timestamp
        fecha_venta = normalize_timestamp(venta["created_at"])
        
        # 2. Calcular total
        total_venta = venta["cantidad"] * venta["precio_unitario"]
        
        # 3. Mapear producto
        producto_info = map_producto(venta["id_producto"])
        if not producto_info:
            ventas_error.append({
                **venta,
                "error": f"Producto {venta['id_producto']} no encontrado en mapeo"
            })
            continue
        
        # 4. Enriquecer con CRM
        segmento_cliente = lookup_segmento(venta["id_cliente"])
        
        # 5. Crear registro transformado
        venta_transformada = {
            "id_venta": venta["id_venta"],
            "fecha_venta": fecha_venta,
            "id_tienda": venta["id_tienda"],
            "id_cliente": venta["id_cliente"],
            "id_producto": producto_info["sku_unificado"],
            "cantidad": venta["cantidad"],
            "precio_unitario": venta["precio_unitario"],
            "total_venta": round(total_venta, 2),
            "canal_venta": "tienda",
            "segmento_cliente": segmento_cliente,
            "created_at": venta["created_at"],
            "fuente": "pos"
        }
        
        # 6. Calcular hash para deduplicaci√≥n
        dedup_hash = calcular_dedup_hash(venta_transformada)
        venta_transformada["dedup_hash"] = dedup_hash
        
        # 7. Validar
        es_valida, error_msg = validar_venta(venta_transformada)
        if not es_valida:
            ventas_error.append({
                **venta,
                "error": error_msg
            })
            continue
        
        # 8. Detectar duplicados
        if venta_transformada["id_venta"] in dedup_set:
            duplicados_detectados += 1
            print(f"[TRANSFORM] ‚ö† Duplicado detectado: id_venta={venta_transformada['id_venta']}")
            continue
        
        dedup_set.add(venta_transformada["id_venta"])
        ventas_validas.append(venta_transformada)
    
    print(f"[TRANSFORM] ‚úì Ventas v√°lidas: {len(ventas_validas)}")
    print(f"[TRANSFORM] ‚ö† Errores: {len(ventas_error)}")
    print(f"[TRANSFORM] ‚ö† Duplicados: {duplicados_detectados}")
    
    return ventas_validas, ventas_error

def load_to_warehouse(ventas: List[Dict], errores: List[Dict]):
    """Simula carga al data warehouse (upsert)"""
    print(f"\n[LOAD] Cargando {len(ventas)} ventas a ventas_consolidadas...")
    
    # Simular upsert SQL
    for venta in ventas:
        sql = f"""
        INSERT INTO ventas_consolidadas 
        (id_venta, fecha_venta, id_tienda, id_cliente, id_producto, 
         cantidad, precio_unitario, total_venta, canal_venta, 
         segmento_cliente, created_at, fuente, dedup_hash)
        VALUES 
        ({venta['id_venta']}, '{venta['fecha_venta']}', {venta['id_tienda']}, 
         {venta['id_cliente']}, '{venta['id_producto']}', {venta['cantidad']}, 
         {venta['precio_unitario']}, {venta['total_venta']}, '{venta['canal_venta']}', 
         '{venta['segmento_cliente']}', '{venta['created_at']}', '{venta['fuente']}',
         '{venta['dedup_hash']}')
        ON CONFLICT (id_venta) DO UPDATE SET
            cantidad = EXCLUDED.cantidad,
            total_venta = EXCLUDED.total_venta,
            segmento_cliente = EXCLUDED.segmento_cliente;
        """
        print(f"  ‚Üí Upsert id_venta={venta['id_venta']}, total=${venta['total_venta']}, segmento={venta['segmento_cliente']}")
    
    print(f"[LOAD] ‚úì Carga completada")
    
    # Cargar errores a tabla de errores
    if errores:
        print(f"\n[LOAD] Cargando {len(errores)} registros a tabla de errores...")
        for error in errores:
            print(f"  ‚Üí Error: {error.get('error', 'desconocido')} - Registro: {error}")

def actualizar_watermark(ventas: List[Dict]) -> str:
    """Actualiza watermark a la √∫ltima fecha procesada"""
    if not ventas:
        return WATERMARK
    
    max_timestamp = max(v["created_at"] for v in ventas)
    print(f"\n[WATERMARK] Actualizando de '{WATERMARK}' a '{max_timestamp}'")
    return max_timestamp

# =============================================================================
# EJECUCI√ìN PRINCIPAL
# =============================================================================

def main():
    print("="*70)
    print("PIPELINE ETL - CARGA INCREMENTAL DE VENTAS POS")
    print("="*70)
    
    # 1. Extract
    ventas_nuevas = extract_ventas_incrementales(WATERMARK)
    
    if not ventas_nuevas:
        print("\n[INFO] No hay ventas nuevas para procesar")
        return
    
    # 2. Transform
    ventas_validas, ventas_error = transform_ventas(ventas_nuevas)
    
    # 3. Load
    load_to_warehouse(ventas_validas, ventas_error)
    
    # 4. Update watermark
    nuevo_watermark = actualizar_watermark(ventas_nuevas)
    
    # 5. Resumen
    print("\n" + "="*70)
    print("RESUMEN DE EJECUCI√ìN")
    print("="*70)
    print(f"Registros extra√≠dos:     {len(ventas_nuevas)}")
    print(f"Registros cargados:      {len(ventas_validas)}")
    print(f"Registros con error:     {len(ventas_error)}")
    print(f"Duplicados detectados:   {len(ventas_nuevas) - len(ventas_validas) - len(ventas_error)}")
    print(f"Nuevo watermark:         {nuevo_watermark}")
    print("="*70)

if __name__ == "__main__":
    main()
```



---

## `setup_warehouse.sql`

```sql
-- ============================================================================
-- SCRIPT DE SETUP DEL DATA WAREHOUSE
-- Crear las tablas de hechos y dimensiones para el pipeline ETL
-- ============================================================================

-- Tabla de hechos principal
CREATE TABLE IF NOT EXISTS ventas_consolidadas (
    id_venta INTEGER PRIMARY KEY,
    fecha_venta DATE NOT NULL,
    id_tienda INTEGER NOT NULL,
    id_cliente INTEGER,
    id_producto VARCHAR(50) NOT NULL,
    cantidad INTEGER NOT NULL CHECK (cantidad >= 0),
    precio_unitario DECIMAL(10,2) NOT NULL CHECK (precio_unitario >= 0),
    total_venta DECIMAL(10,2) NOT NULL,
    canal_venta VARCHAR(20) NOT NULL CHECK (canal_venta IN ('online', 'tienda')),
    segmento_cliente VARCHAR(20),
    created_at TIMESTAMP NOT NULL,
    fuente VARCHAR(20) NOT NULL CHECK (fuente IN ('pos', 'web', 'otros')),
    dedup_hash VARCHAR(32),
    carga_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    CONSTRAINT fk_tienda FOREIGN KEY (id_tienda) REFERENCES dim_tienda(id_tienda),
    CONSTRAINT fk_producto FOREIGN KEY (id_producto) REFERENCES dim_producto(sku_unificado),
    CONSTRAINT fk_cliente FOREIGN KEY (id_cliente) REFERENCES dim_cliente(id_cliente),
    CONSTRAINT fk_fecha FOREIGN KEY (fecha_venta) REFERENCES dim_fecha(fecha)
);

-- √çndices para mejorar performance
CREATE INDEX idx_ventas_fecha ON ventas_consolidadas(fecha_venta);
CREATE INDEX idx_ventas_tienda ON ventas_consolidadas(id_tienda);
CREATE INDEX idx_ventas_producto ON ventas_consolidadas(id_producto);
CREATE INDEX idx_ventas_cliente ON ventas_consolidadas(id_cliente);
CREATE INDEX idx_ventas_dedup ON ventas_consolidadas(dedup_hash);
CREATE INDEX idx_ventas_created_at ON ventas_consolidadas(created_at);

-- ============================================================================
-- TABLAS DIMENSIONALES
-- ============================================================================

-- Dimensi√≥n de tiendas
CREATE TABLE IF NOT EXISTS dim_tienda (
    id_tienda INTEGER PRIMARY KEY,
    nombre VARCHAR(100) NOT NULL,
    region VARCHAR(50),
    ciudad VARCHAR(50),
    tipo VARCHAR(30) CHECK (tipo IN ('flagship', 'outlet', 'pop-up', 'regular')),
    fecha_apertura DATE,
    activa BOOLEAN DEFAULT TRUE,
    ultima_actualizacion TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Datos de ejemplo para dim_tienda
INSERT INTO dim_tienda (id_tienda, nombre, region, ciudad, tipo, fecha_apertura) VALUES
(3, 'Tienda Centro', 'Metropolitana', 'Santiago', 'flagship', '2020-01-15'),
(5, 'Tienda Mall Plaza', 'Metropolitana', 'Santiago', 'regular', '2019-05-20'),
(8, 'Outlet Vi√±a', 'Valpara√≠so', 'Vi√±a del Mar', 'outlet', '2021-03-10')
ON CONFLICT (id_tienda) DO NOTHING;

-- Dimensi√≥n de productos
CREATE TABLE IF NOT EXISTS dim_producto (
    sku_unificado VARCHAR(50) PRIMARY KEY,
    nombre VARCHAR(200) NOT NULL,
    categoria VARCHAR(50),
    subcategoria VARCHAR(50),
    marca VARCHAR(50),
    precio_sugerido DECIMAL(10,2),
    activo BOOLEAN DEFAULT TRUE,
    ultima_actualizacion TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Datos de ejemplo para dim_producto
INSERT INTO dim_producto (sku_unificado, nombre, categoria, subcategoria, marca, precio_sugerido) VALUES
('PROD_001', 'Camiseta B√°sica', 'Ropa', 'Camisetas', 'BasicWear', 25.50),
('PROD_002', 'Zapatillas Running', 'Calzado', 'Deportivo', 'SportMax', 89.99),
('PROD_003', 'Calcetines Pack 3', 'Accesorios', 'Calceter√≠a', 'ComfortPlus', 15.00),
('PROD_004', 'Gorra Deportiva', 'Accesorios', 'Gorras', 'SportMax', 45.00)
ON CONFLICT (sku_unificado) DO NOTHING;

-- Dimensi√≥n de clientes
CREATE TABLE IF NOT EXISTS dim_cliente (
    id_cliente INTEGER PRIMARY KEY,
    nombre VARCHAR(100),
    email VARCHAR(150),
    segmento VARCHAR(20) CHECK (segmento IN ('vip', 'premium', 'regular', 'nuevo', 'sin_clasificar', 'anonimo')),
    fecha_registro DATE,
    activo BOOLEAN DEFAULT TRUE,
    ultima_actualizacion TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Datos de ejemplo para dim_cliente
INSERT INTO dim_cliente (id_cliente, nombre, email, segmento, fecha_registro) VALUES
(2341, 'Ana Garc√≠a', 'ana.garcia@email.com', 'premium', '2022-03-15'),
(1523, 'Carlos L√≥pez', 'carlos.lopez@email.com', 'regular', '2023-01-20'),
(4567, 'Mar√≠a Rodr√≠guez', 'maria.rodriguez@email.com', 'vip', '2021-11-05')
ON CONFLICT (id_cliente) DO NOTHING;

-- Dimensi√≥n de fecha (tabla calendario)
CREATE TABLE IF NOT EXISTS dim_fecha (
    fecha DATE PRIMARY KEY,
    anio INTEGER NOT NULL,
    mes INTEGER NOT NULL CHECK (mes BETWEEN 1 AND 12),
    dia INTEGER NOT NULL CHECK (dia BETWEEN 1 AND 31),
    trimestre INTEGER NOT NULL CHECK (trimestre BETWEEN 1 AND 4),
    semana INTEGER NOT NULL,
    dia_semana INTEGER NOT NULL CHECK (dia_semana BETWEEN 1 AND 7),
    nombre_dia VARCHAR(20),
    nombre_mes VARCHAR(20),
    es_fin_semana BOOLEAN,
    es_festivo BOOLEAN DEFAULT FALSE,
    nombre_festivo VARCHAR(100)
);

-- Procedimiento para poblar dim_fecha (ejemplo simplificado)
-- En producci√≥n, esto deber√≠a generar varios a√±os de datos
INSERT INTO dim_fecha (fecha, anio, mes, dia, trimestre, semana, dia_semana, nombre_dia, nombre_mes, es_fin_semana)
SELECT 
    fecha,
    EXTRACT(YEAR FROM fecha) as anio,
    EXTRACT(MONTH FROM fecha) as mes,
    EXTRACT(DAY FROM fecha) as dia,
    EXTRACT(QUARTER FROM fecha) as trimestre,
    EXTRACT(WEEK FROM fecha) as semana,
    EXTRACT(DOW FROM fecha) + 1 as dia_semana,
    TO_CHAR(fecha, 'Day') as nombre_dia,
    TO_CHAR(fecha, 'Month') as nombre_mes,
    EXTRACT(DOW FROM fecha) IN (0, 6) as es_fin_semana
FROM generate_series('2025-01-01'::date, '2025-12-31'::date, '1 day'::interval) fecha
ON CONFLICT (fecha) DO NOTHING;

-- ============================================================================
-- TABLA DE MAPEO DE PRODUCTOS (para normalizaci√≥n de SKUs)
-- ============================================================================

CREATE TABLE IF NOT EXISTS producto_map (
    id_mapeo SERIAL PRIMARY KEY,
    sistema VARCHAR(50) NOT NULL,
    id_sistema VARCHAR(100) NOT NULL,
    sku_unificado VARCHAR(50) NOT NULL,
    activo BOOLEAN DEFAULT TRUE,
    fecha_creacion TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    UNIQUE(sistema, id_sistema),
    CONSTRAINT fk_producto_unificado FOREIGN KEY (sku_unificado) REFERENCES dim_producto(sku_unificado)
);

-- Datos de ejemplo para mapeo
INSERT INTO producto_map (sistema, id_sistema, sku_unificado) VALUES
('pos', 'POS_SKU_789', 'PROD_001'),
('pos', 'POS_SKU_456', 'PROD_002'),
('pos', 'POS_SKU_123', 'PROD_003'),
('pos', 'POS_SKU_999', 'PROD_004'),
('inventario', 'INV_PROD_001', 'PROD_001'),
('inventario', 'INV_PROD_002', 'PROD_002'),
('inventario', 'INV_PROD_003', 'PROD_003'),
('inventario', 'INV_PROD_004', 'PROD_004')
ON CONFLICT (sistema, id_sistema) DO NOTHING;

-- ============================================================================
-- TABLA DE ERRORES (para auditor√≠a)
-- ============================================================================

CREATE TABLE IF NOT EXISTS staging_errors (
    id_error SERIAL PRIMARY KEY,
    fuente VARCHAR(50) NOT NULL,
    registro_json JSONB NOT NULL,
    error_descripcion TEXT NOT NULL,
    error_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    procesado BOOLEAN DEFAULT FALSE
);

CREATE INDEX idx_errors_timestamp ON staging_errors(error_timestamp);
CREATE INDEX idx_errors_fuente ON staging_errors(fuente);

-- ============================================================================
-- TABLA DE WATERMARKS (para cargas incrementales)
-- ============================================================================

CREATE TABLE IF NOT EXISTS etl_watermarks (
    fuente VARCHAR(50) PRIMARY KEY,
    ultimo_timestamp TIMESTAMP NOT NULL,
    ultima_actualizacion TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    registros_procesados INTEGER DEFAULT 0
);

-- Inicializar watermarks
INSERT INTO etl_watermarks (fuente, ultimo_timestamp) VALUES
('pos_ventas', '2025-01-15 10:00:00'),
('web_logs', '2025-01-15 00:00:00'),
('inventario', '2025-01-14 00:00:00'),
('crm', '2025-01-08 00:00:00')
ON CONFLICT (fuente) DO NOTHING;

-- ============================================================================
-- TABLA DE INVENTARIO (snapshot diario)
-- ============================================================================

CREATE TABLE IF NOT EXISTS dim_inventario (
    id_inventario SERIAL PRIMARY KEY,
    sku_unificado VARCHAR(50) NOT NULL,
    ubicacion VARCHAR(50) NOT NULL,
    stock INTEGER NOT NULL CHECK (stock >= 0),
    stock_minimo INTEGER,
    fecha_snapshot DATE NOT NULL,
    
    UNIQUE(sku_unificado, ubicacion, fecha_snapshot),
    CONSTRAINT fk_inv_producto FOREIGN KEY (sku_unificado) REFERENCES dim_producto(sku_unificado)
);

CREATE INDEX idx_inventario_fecha ON dim_inventario(fecha_snapshot);
CREATE INDEX idx_inventario_sku ON dim_inventario(sku_unificado);

-- ============================================================================
-- VISTAS √öTILES PARA AN√ÅLISIS
-- ============================================================================

-- Vista de ventas enriquecidas
CREATE OR REPLACE VIEW v_ventas_detalle AS
SELECT 
    v.id_venta,
    v.fecha_venta,
    f.nombre_mes,
    f.anio,
    f.trimestre,
    f.es_fin_semana,
    t.nombre as nombre_tienda,
    t.region,
    t.ciudad,
    c.nombre as nombre_cliente,
    c.email,
    v.segmento_cliente,
    p.nombre as nombre_producto,
    p.categoria,
    p.marca,
    v.cantidad,
    v.precio_unitario,
    v.total_venta,
    v.canal_venta,
    v.fuente
FROM ventas_consolidadas v
LEFT JOIN dim_fecha f ON v.fecha_venta = f.fecha
LEFT JOIN dim_tienda t ON v.id_tienda = t.id_tienda
LEFT JOIN dim_cliente c ON v.id_cliente = c.id_cliente
LEFT JOIN dim_producto p ON v.id_producto = p.sku_unificado;

-- Vista de resumen de ventas por d√≠a y tienda
CREATE OR REPLACE VIEW v_ventas_resumen_diario AS
SELECT 
    fecha_venta,
    id_tienda,
    COUNT(*) as num_transacciones,
    SUM(cantidad) as unidades_vendidas,
    SUM(total_venta) as total_ventas,
    AVG(total_venta) as ticket_promedio,
    COUNT(DISTINCT id_cliente) as clientes_unicos
FROM ventas_consolidadas
GROUP BY fecha_venta, id_tienda;

-- ============================================================================
-- COMENTARIOS EN TABLAS (documentaci√≥n)
-- ============================================================================

COMMENT ON TABLE ventas_consolidadas IS 'Tabla de hechos principal con todas las ventas consolidadas de diferentes fuentes';
COMMENT ON COLUMN ventas_consolidadas.dedup_hash IS 'Hash MD5 para detecci√≥n de duplicados basado en campos cr√≠ticos';
COMMENT ON COLUMN ventas_consolidadas.fuente IS 'Sistema origen: pos, web, otros';

COMMENT ON TABLE dim_fecha IS 'Dimensi√≥n calendario con todos los d√≠as del a√±o y atributos temporales';
COMMENT ON TABLE producto_map IS 'Mapeo de SKUs entre diferentes sistemas al SKU unificado';
COMMENT ON TABLE etl_watermarks IS 'Marcas de agua para cargas incrementales por fuente';

-- ============================================================================
-- SCRIPT COMPLETADO
-- ============================================================================

SELECT 'Setup completado exitosamente' as mensaje;

```

###  Quiz del Dia 1 
![quiz](img/quiz.png)


